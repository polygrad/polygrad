<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>polygrad vs tf.js — Visual Comparison</title>
<style>
* { box-sizing: border-box; margin: 0; padding: 0; }
body {
  background: #0f1117; color: #e1e4e8;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
  padding-top: 64px;
}

/* Top bar */
.top-bar {
  position: fixed; top: 0; left: 0; right: 0; z-index: 100;
  background: #161b22; border-bottom: 1px solid #30363d;
  padding: 12px 24px; display: flex; align-items: center; gap: 16px;
  height: 60px;
}
.top-bar h1 { font-size: 16px; color: #f0f6fc; white-space: nowrap; }
.size-badges { display: flex; gap: 8px; }
.size-badge {
  font-size: 11px; padding: 3px 10px; border-radius: 12px;
  font-weight: 600; font-family: 'SF Mono', 'Fira Code', monospace;
}
.size-badge.polygrad { background: rgba(88,166,255,0.15); color: #58a6ff; }
.size-badge.tfjs { background: rgba(255,166,87,0.15); color: #ffa657; }
.run-btn {
  background: #238636; border: 1px solid #2ea043; color: #fff;
  padding: 6px 16px; border-radius: 6px; font-size: 13px; font-weight: 600;
  cursor: pointer; white-space: nowrap;
}
.run-btn:hover { background: #2ea043; }
.run-btn:disabled { opacity: 0.5; cursor: not-allowed; }
.progress-dots { display: flex; gap: 6px; flex-shrink: 0; }
.dot {
  width: 28px; height: 28px; border-radius: 50%; display: flex;
  align-items: center; justify-content: center;
  font-size: 11px; font-weight: 600;
  border: 2px solid #30363d; color: #484f58; background: transparent;
  transition: all 0.3s;
}
.dot.running { border-color: #58a6ff; color: #58a6ff; animation: pulse 1.2s infinite; }
.dot.pass { border-color: #3fb950; color: #3fb950; background: rgba(63,185,80,0.1); }
.dot.fail { border-color: #f85149; color: #f85149; background: rgba(248,81,73,0.1); }
@keyframes pulse {
  0%, 100% { box-shadow: 0 0 0 0 rgba(88,166,255,0.4); }
  50% { box-shadow: 0 0 0 6px rgba(88,166,255,0); }
}
.status-text { font-size: 13px; color: #8b949e; white-space: nowrap; margin-left: auto; }

/* Test blocks */
.test-block {
  background: #161b22; border: 1px solid #30363d; border-radius: 8px;
  padding: 20px; margin: 16px 24px;
}
.test-header { display: flex; align-items: center; gap: 12px; margin-bottom: 4px; }
.test-header h3 { font-size: 15px; color: #f0f6fc; }
.badge {
  font-size: 11px; padding: 2px 8px; border-radius: 4px; font-weight: 600;
  white-space: nowrap;
}
.badge.pending { background: rgba(139,148,158,0.15); color: #484f58; }
.badge.pass { background: rgba(63,185,80,0.15); color: #3fb950; }
.badge.fail { background: rgba(248,81,73,0.15); color: #f85149; }
.description { font-size: 13px; color: #8b949e; margin-bottom: 8px; }
.canvas-wrap { background: #0d1117; border-radius: 6px; overflow: hidden; margin-bottom: 8px; }
.canvas-wrap canvas { display: block; width: 100%; height: 280px; }
.canvas-row { display: flex; gap: 1px; background: #0d1117; border-radius: 6px; overflow: hidden; margin-bottom: 8px; }
.canvas-row .canvas-wrap { flex: 1; margin-bottom: 0; border-radius: 0; }
.canvas-row canvas { height: 240px; }
.details {
  font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
  font-size: 12px; color: #79c0ff; line-height: 1.6;
}
.details .label { color: #8b949e; }
.details .pass-val { color: #3fb950; }
.details .fail-val { color: #f85149; }
.details .polygrad-val { color: #58a6ff; }
.details .tfjs-val { color: #ffa657; }

.result-table {
  width: 100%; border-collapse: collapse; font-size: 12px;
  font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
  margin-bottom: 8px;
}
.result-table th {
  background: #0d1117; color: #8b949e; text-align: left;
  padding: 6px 10px; border-bottom: 1px solid #30363d; font-weight: 600;
}
.result-table td {
  padding: 5px 10px; border-bottom: 1px solid #21262d; color: #e1e4e8;
}
.result-table .cell-pass { color: #3fb950; }
.result-table .cell-fail { color: #f85149; }
.result-table .cell-polygrad { color: #58a6ff; }
.result-table .cell-tfjs { color: #ffa657; }
</style>
</head>
<body>

<div class="top-bar">
  <h1>polygrad vs tf.js</h1>
  <div class="size-badges">
    <span class="size-badge polygrad" id="polygradSize">polygrad: loading...</span>
    <span class="size-badge tfjs" id="tfjsSize">tf.js: loading...</span>
  </div>
  <button class="run-btn" id="runBtn" onclick="runAllTests()" disabled>Run All</button>
  <div class="progress-dots" id="dots"></div>
  <div class="status-text" id="statusText">Loading libraries...</div>
</div>

<div id="testContainer"></div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4/dist/tf.min.js"></script>
<script src="../../../build/polygrad.js"></script>
<script>
'use strict'

// ── Canvas utilities (adapted from stoch visual_tests.html) ──

function setupCanvas(canvas) {
  const dpr = window.devicePixelRatio || 1
  const rect = canvas.getBoundingClientRect()
  canvas.width = rect.width * dpr
  canvas.height = rect.height * dpr
  const ctx = canvas.getContext('2d')
  ctx.scale(dpr, dpr)
  return { ctx, w: rect.width, h: rect.height }
}

const PAD = { top: 24, right: 20, bottom: 32, left: 50 }

function drawMultiHistogram(c, w, h, datasets, opts = {}) {
  const nBins = opts.nBins || 40
  const pL = PAD.left, pR = PAD.right, pT = PAD.top, pB = PAD.bottom
  const pw = w - pL - pR, ph = h - pT - pB

  let lo = Infinity, hi = -Infinity
  for (const ds of datasets) {
    for (const v of ds.data) { if (v < lo) lo = v; if (v > hi) hi = v }
  }
  if (lo === hi) { lo -= 1; hi += 1 }
  const binW = (hi - lo) / nBins

  const allBins = datasets.map(ds => {
    const bins = new Array(nBins).fill(0)
    for (const v of ds.data) {
      let idx = Math.floor((v - lo) / binW)
      if (idx < 0) idx = 0; if (idx >= nBins) idx = nBins - 1
      bins[idx]++
    }
    return bins
  })
  let maxBin = 0
  for (const bins of allBins) for (const b of bins) if (b > maxBin) maxBin = b

  c.fillStyle = '#0d1117'; c.fillRect(0, 0, w, h)

  c.strokeStyle = '#21262d'; c.lineWidth = 1
  for (let i = 0; i <= 4; i++) {
    const y = pT + (ph * i / 4)
    c.beginPath(); c.moveTo(pL, y); c.lineTo(pL + pw, y); c.stroke()
  }

  for (let d = 0; d < datasets.length; d++) {
    c.fillStyle = datasets[d].color || '#58a6ff'; c.globalAlpha = 0.5
    for (let i = 0; i < nBins; i++) {
      const x = pL + (i / nBins) * pw
      const bw = pw / nBins - 1
      const bh = (allBins[d][i] / maxBin) * ph
      c.fillRect(x, pT + ph - bh, bw, bh)
    }
  }
  c.globalAlpha = 1

  // Axes
  c.strokeStyle = '#484f58'; c.lineWidth = 1
  c.beginPath()
  c.moveTo(pL, pT + ph); c.lineTo(pL + pw, pT + ph)
  c.moveTo(pL, pT); c.lineTo(pL, pT + ph)
  c.stroke()

  c.fillStyle = '#8b949e'; c.font = '10px sans-serif'; c.textAlign = 'center'
  for (let i = 0; i <= 5; i++) {
    c.fillText((lo + (i / 5) * (hi - lo)).toFixed(1), pL + (i / 5) * pw, pT + ph + 14)
  }

  // Legend
  let lx = pL + 8
  for (const ds of datasets) {
    c.fillStyle = ds.color
    c.fillRect(lx, pT + 4, 10, 10)
    c.fillStyle = '#e1e4e8'; c.font = '10px sans-serif'; c.textAlign = 'left'
    c.fillText(ds.label, lx + 14, pT + 13)
    lx += c.measureText(ds.label).width + 30
  }

  // Title
  if (opts.title) {
    c.fillStyle = '#e1e4e8'; c.font = '12px sans-serif'; c.textAlign = 'center'
    c.fillText(opts.title, w / 2, 14)
  }
}

function drawLineChart(c, w, h, series, opts = {}) {
  const pL = PAD.left, pR = PAD.right, pT = PAD.top, pB = PAD.bottom
  const pw = w - pL - pR, ph = h - pT - pB

  let xLo = Infinity, xHi = -Infinity, yLo = Infinity, yHi = -Infinity
  for (const s of series) {
    for (const x of s.xs) { if (x < xLo) xLo = x; if (x > xHi) xHi = x }
    for (const y of s.ys) { if (isFinite(y)) { if (y < yLo) yLo = y; if (y > yHi) yHi = y } }
  }
  if (opts.yMin != null) yLo = opts.yMin
  if (opts.yMax != null) yHi = opts.yMax
  const yPad = (yHi - yLo) * 0.05 || 0.5
  yLo -= yPad; yHi += yPad

  const toX = v => pL + ((v - xLo) / (xHi - xLo || 1)) * pw
  const toY = v => pT + ph - ((v - yLo) / (yHi - yLo || 1)) * ph

  c.fillStyle = '#0d1117'; c.fillRect(0, 0, w, h)

  c.strokeStyle = '#21262d'; c.lineWidth = 1
  for (let i = 0; i <= 4; i++) {
    const y = pT + (ph * i / 4)
    c.beginPath(); c.moveTo(pL, y); c.lineTo(pL + pw, y); c.stroke()
  }

  for (const s of series) {
    c.strokeStyle = s.color || '#58a6ff'
    c.lineWidth = s.lineWidth || 2
    if (s.dashed) c.setLineDash([6, 4])
    c.beginPath()
    for (let i = 0; i < s.xs.length; i++) {
      const px = toX(s.xs[i]), py = toY(s.ys[i])
      if (i === 0) c.moveTo(px, py); else c.lineTo(px, py)
    }
    c.stroke(); c.setLineDash([])
  }

  // Axes
  c.strokeStyle = '#484f58'; c.lineWidth = 1
  c.beginPath()
  c.moveTo(pL, pT + ph); c.lineTo(pL + pw, pT + ph)
  c.moveTo(pL, pT); c.lineTo(pL, pT + ph)
  c.stroke()

  c.fillStyle = '#8b949e'; c.font = '10px sans-serif'; c.textAlign = 'center'
  for (let i = 0; i <= 5; i++) {
    const val = xLo + (i / 5) * (xHi - xLo)
    c.fillText(Number.isInteger(val) ? val.toString() : val.toFixed(1), pL + (i / 5) * pw, pT + ph + 14)
  }
  c.textAlign = 'right'
  for (let i = 0; i <= 4; i++) {
    const val = yHi - (i / 4) * (yHi - yLo)
    c.fillText(val.toFixed(2), pL - 5, pT + (i / 4) * ph + 4)
  }

  // Legend
  let lx = pL + 8
  for (const s of series) {
    if (!s.label) continue
    c.strokeStyle = s.color || '#58a6ff'; c.lineWidth = 2
    if (s.dashed) c.setLineDash([4, 3])
    c.beginPath(); c.moveTo(lx, pT + 10); c.lineTo(lx + 16, pT + 10); c.stroke()
    c.setLineDash([])
    lx += 20
    c.fillStyle = '#e1e4e8'; c.font = '10px sans-serif'; c.textAlign = 'left'
    c.fillText(s.label, lx, pT + 13)
    lx += c.measureText(s.label).width + 16
  }

  if (opts.xLabel) {
    c.fillStyle = '#8b949e'; c.font = '11px sans-serif'; c.textAlign = 'center'
    c.fillText(opts.xLabel, pL + pw / 2, h - 4)
  }
  if (opts.yLabel) {
    c.save(); c.fillStyle = '#8b949e'; c.font = '11px sans-serif'
    c.translate(12, pT + ph / 2); c.rotate(-Math.PI / 2)
    c.textAlign = 'center'; c.fillText(opts.yLabel, 0, 0)
    c.restore()
  }
}

function drawBarChart(c, w, h, groups, opts = {}) {
  const pL = PAD.left + 10, pR = PAD.right, pT = PAD.top, pB = PAD.bottom + 8
  const pw = w - pL - pR, ph = h - pT - pB

  let maxVal = 0
  for (const g of groups) for (const b of g.bars) if (b.value > maxVal) maxVal = b.value
  maxVal *= 1.15

  c.fillStyle = '#0d1117'; c.fillRect(0, 0, w, h)

  // Grid
  c.strokeStyle = '#21262d'; c.lineWidth = 1
  for (let i = 0; i <= 4; i++) {
    const y = pT + (ph * i / 4)
    c.beginPath(); c.moveTo(pL, y); c.lineTo(pL + pw, y); c.stroke()
  }

  const nGroups = groups.length
  const groupW = pw / nGroups
  const nBars = groups[0].bars.length
  const barW = Math.min(groupW * 0.7 / nBars, 40)
  const clusterW = barW * nBars + 4 * (nBars - 1)

  for (let g = 0; g < nGroups; g++) {
    const gx = pL + g * groupW + groupW / 2 - clusterW / 2
    for (let b = 0; b < groups[g].bars.length; b++) {
      const bar = groups[g].bars[b]
      const x = gx + b * (barW + 4)
      const bh = (bar.value / maxVal) * ph
      c.fillStyle = bar.color || '#58a6ff'
      c.globalAlpha = 0.8
      c.fillRect(x, pT + ph - bh, barW, bh)
      c.globalAlpha = 1

      // Value label
      if (bh > 14) {
        c.fillStyle = '#e1e4e8'; c.font = '9px monospace'; c.textAlign = 'center'
        c.fillText(bar.value < 1 ? bar.value.toFixed(2) : bar.value.toFixed(1),
          x + barW / 2, pT + ph - bh + 12)
      }
    }
    // Group label
    c.fillStyle = '#8b949e'; c.font = '10px sans-serif'; c.textAlign = 'center'
    c.fillText(groups[g].label, pL + g * groupW + groupW / 2, pT + ph + 14)
  }

  // Axes
  c.strokeStyle = '#484f58'; c.lineWidth = 1
  c.beginPath()
  c.moveTo(pL, pT + ph); c.lineTo(pL + pw, pT + ph)
  c.moveTo(pL, pT); c.lineTo(pL, pT + ph)
  c.stroke()

  // Y axis labels
  c.fillStyle = '#8b949e'; c.font = '10px sans-serif'; c.textAlign = 'right'
  for (let i = 0; i <= 4; i++) {
    const val = maxVal * (1 - i / 4)
    c.fillText(val < 1 ? val.toFixed(2) : val.toFixed(1), pL - 5, pT + (i / 4) * ph + 4)
  }

  // Legend
  let lx = pL + 8
  const seen = new Set()
  for (const g of groups) for (const b of g.bars) {
    if (seen.has(b.label)) continue; seen.add(b.label)
    c.fillStyle = b.color; c.fillRect(lx, pT + 4, 10, 10)
    c.fillStyle = '#e1e4e8'; c.font = '10px sans-serif'; c.textAlign = 'left'
    c.fillText(b.label, lx + 14, pT + 13)
    lx += c.measureText(b.label).width + 30
  }

  if (opts.yLabel) {
    c.save(); c.fillStyle = '#8b949e'; c.font = '11px sans-serif'
    c.translate(12, pT + ph / 2); c.rotate(-Math.PI / 2)
    c.textAlign = 'center'; c.fillText(opts.yLabel, 0, 0)
    c.restore()
  }
}

function drawHistogram(c, w, h, data, opts = {}) {
  const nBins = opts.nBins || 40
  const color = opts.color || '#1f6feb'
  const title = opts.title || ''
  const pL = PAD.left, pR = PAD.right, pT = PAD.top, pB = PAD.bottom
  const pw = w - pL - pR, ph = h - pT - pB

  let lo = Math.min(...data), hi = Math.max(...data)
  if (hi === lo) { lo -= 1; hi += 1 }
  const binW = (hi - lo) / nBins
  const bins = new Array(nBins).fill(0)
  for (const v of data) {
    let idx = Math.floor((v - lo) / binW)
    if (idx < 0) idx = 0; if (idx >= nBins) idx = nBins - 1
    bins[idx]++
  }
  const maxBin = Math.max(...bins)

  c.fillStyle = '#0d1117'; c.fillRect(0, 0, w, h)

  c.strokeStyle = '#21262d'; c.lineWidth = 1
  for (let i = 0; i <= 4; i++) {
    const y = pT + (ph * i / 4)
    c.beginPath(); c.moveTo(pL, y); c.lineTo(pL + pw, y); c.stroke()
  }

  c.fillStyle = color; c.globalAlpha = 0.7
  for (let i = 0; i < nBins; i++) {
    const x = pL + (i / nBins) * pw
    const bw = pw / nBins - 1
    const bh = (bins[i] / maxBin) * ph
    c.fillRect(x, pT + ph - bh, bw, bh)
  }
  c.globalAlpha = 1

  c.strokeStyle = '#484f58'; c.lineWidth = 1
  c.beginPath()
  c.moveTo(pL, pT + ph); c.lineTo(pL + pw, pT + ph)
  c.moveTo(pL, pT); c.lineTo(pL, pT + ph)
  c.stroke()

  c.fillStyle = '#8b949e'; c.font = '10px sans-serif'; c.textAlign = 'center'
  for (let i = 0; i <= 5; i++) {
    c.fillText((lo + (i / 5) * (hi - lo)).toFixed(2), pL + (i / 5) * pw, pT + ph + 14)
  }

  if (title) {
    c.fillStyle = '#e1e4e8'; c.font = '12px sans-serif'; c.textAlign = 'center'
    c.fillText(title, w / 2, 14)
  }
}

// ── Helpers ──

function randFloat32(n, lo = -5, hi = 5) {
  const a = new Float32Array(n)
  for (let i = 0; i < n; i++) a[i] = lo + Math.random() * (hi - lo)
  return a
}

function maxAbsError(a, b) {
  let mx = 0
  for (let i = 0; i < a.length; i++) {
    const d = Math.abs(a[i] - b[i])
    if (d > mx) mx = d
  }
  return mx
}

function mean(arr) {
  let s = 0; for (let i = 0; i < arr.length; i++) s += arr[i]; return s / arr.length
}

function tensorDataAndDispose(tensor) {
  const raw = tensor.dataSync()
  const out = new Float32Array(raw.length)
  out.set(raw)
  tensor.dispose()
  return out
}

async function benchmarkIterationsByTime(runOnce, opts = {}) {
  const warmupMs = opts.warmupMs == null ? 200 : opts.warmupMs
  const sampleMs = opts.sampleMs == null ? 800 : opts.sampleMs
  const minIters = opts.minIters == null ? 2 : opts.minIters

  const warmupStart = performance.now()
  while (performance.now() - warmupStart < warmupMs) {
    await runOnce()
  }

  const sampleStart = performance.now()
  const times = []
  while (performance.now() - sampleStart < sampleMs || times.length < minIters) {
    const t0 = performance.now()
    await runOnce()
    times.push(performance.now() - t0)
  }

  const totalMs = times.reduce((a, b) => a + b, 0)
  const iterPerSec = totalMs > 0 ? (times.length * 1000) / totalMs : 0

  return {
    iterations: times.length,
    totalMs,
    avgMs: mean(times),
    iterPerSec
  }
}

// ── polygrad WASM wrapper (browser-compatible, adapted from index.js) ──

let polygradModule = null
let _ffi = null

async function initPolygrad() {
  if (polygradModule) return
  polygradModule = await PolygradModule({
    locateFile: (path) => '../../../build/' + path
  })

  _ffi = {
    poly_ctx_new: polygradModule.cwrap('poly_ctx_new', 'number', []),
    poly_ctx_destroy: polygradModule.cwrap('poly_ctx_destroy', null, ['number']),
    poly_op_count: polygradModule.cwrap('poly_op_count', 'number', []),
    poly_op_name: polygradModule.cwrap('poly_op_name', 'string', ['number']),
    poly_const_float: polygradModule.cwrap('poly_const_float', 'number', ['number', 'number']),
    poly_const_int: (ctx, val) => polygradModule._poly_const_int(ctx, BigInt(val)),
    poly_alu1: polygradModule.cwrap('poly_alu1', 'number', ['number', 'number', 'number']),
    poly_alu2: polygradModule.cwrap('poly_alu2', 'number', ['number', 'number', 'number', 'number']),
    poly_alu3: polygradModule.cwrap('poly_alu3', 'number', ['number', 'number', 'number', 'number', 'number']),
    poly_store_val: polygradModule.cwrap('poly_store_val', 'number', ['number', 'number', 'number']),
    poly_sink1: polygradModule.cwrap('poly_sink1', 'number', ['number', 'number']),
    poly_buffer_f32: (ctx, size) => polygradModule._poly_buffer_f32(ctx, BigInt(size)),
    poly_reshape: polygradModule.cwrap('poly_reshape', 'number', ['number', 'number', 'number', 'number']),
    poly_expand: polygradModule.cwrap('poly_expand', 'number', ['number', 'number', 'number', 'number']),
    poly_reduce_axis: polygradModule.cwrap('poly_reduce_axis', 'number', ['number', 'number', 'number', 'number', 'number']),
    poly_permute: polygradModule.cwrap('poly_permute', 'number', ['number', 'number', 'number', 'number']),
    poly_shrink: polygradModule.cwrap('poly_shrink', 'number', ['number', 'number', 'number', 'number']),
    poly_flip: polygradModule.cwrap('poly_flip', 'number', ['number', 'number', 'number', 'number']),
    poly_pad: polygradModule.cwrap('poly_pad', 'number', ['number', 'number', 'number', 'number']),
    poly_grad: polygradModule.cwrap('poly_grad', 'number', ['number', 'number', 'number']),
    poly_render_kernel_wasm: polygradModule.cwrap('poly_render_kernel_wasm', 'number', ['number', 'number', 'number', 'number']),
    poly_kernel_buf: polygradModule.cwrap('poly_kernel_buf', 'number', ['number', 'number']),
    OPS: {}
  }

  const opCount = _ffi.poly_op_count()
  for (let i = 0; i < opCount; i++) {
    const name = _ffi.poly_op_name(i)
    if (name) _ffi.OPS[name] = i
  }

  PolygradTensor._defaultCtx = _ffi.poly_ctx_new()
}

function writeInt64Array(arr) {
  const ptr = polygradModule._malloc(arr.length * 8)
  for (let i = 0; i < arr.length; i++) {
    polygradModule.setValue(ptr + i * 8, arr[i] & 0xFFFFFFFF, 'i32')
    polygradModule.setValue(ptr + i * 8 + 4, arr[i] < 0 ? -1 : 0, 'i32')
  }
  return ptr
}

function callWithInt64Array(fn, ctx, uop, arr, ...extra) {
  const ptr = writeInt64Array(arr)
  const result = fn(ctx, uop, ptr, ...extra)
  polygradModule._free(ptr)
  return result
}

const mathImports = {
  exp2f: (x) => Math.pow(2, x),
  log2f: (x) => Math.log2(x),
  sinf: (x) => Math.sin(x)
}

// Execution cache: hash(wasmBytes) → { instance, memory, memPages, offsets, ... }
const _execCache = new Map()

function hashBytes(bytes) {
  let h = 0x811c9dc5
  for (let i = 0; i < bytes.length; i++) {
    h ^= bytes[i]
    h = Math.imul(h, 0x01000193)
  }
  return h >>> 0
}

function _renderAndExec(ctx, sink, outBuf, numel, bufferDataFn) {
  const wasmLenPtr = polygradModule._malloc(4)
  const nBufsPtr = polygradModule._malloc(4)
  const wasmPtr = _ffi.poly_render_kernel_wasm(ctx, sink, wasmLenPtr, nBufsPtr)
  const wasmLen = polygradModule.getValue(wasmLenPtr, 'i32')
  const nBufs = polygradModule.getValue(nBufsPtr, 'i32')
  polygradModule._free(wasmLenPtr)
  polygradModule._free(nBufsPtr)
  if (!wasmPtr || wasmLen === 0) throw new Error('poly_render_kernel_wasm failed')

  const bufData = new Array(nBufs)
  for (let i = 0; i < nBufs; i++) {
    const bufUop = _ffi.poly_kernel_buf(ctx, i)
    const data = bufferDataFn(bufUop)
    if (!data) throw new Error(`No data binding for kernel buffer param ${i}`)
    bufData[i] = data
  }

  const wasmBytes = new Uint8Array(wasmLen)
  wasmBytes.set(polygradModule.HEAPU8.subarray(wasmPtr, wasmPtr + wasmLen))
  polygradModule._free(wasmPtr)

  const key = hashBytes(wasmBytes)
  let exec = _execCache.get(key)

  if (!exec) {
    const offsets = new Array(nBufs)
    let totalBytes = 0
    for (let i = 0; i < nBufs; i++) {
      offsets[i] = totalBytes
      totalBytes += bufData[i].length * 4
    }
    const neededPages = Math.max(1, Math.ceil(totalBytes / 65536))
    const memory = new WebAssembly.Memory({ initial: neededPages })
    const module = new WebAssembly.Module(wasmBytes)
    const instance = new WebAssembly.Instance(module, {
      env: { memory }, math: mathImports
    })
    exec = { instance, memory, memPages: neededPages, nBufs, offsets, totalBytes }
    _execCache.set(key, exec)
  }

  const memView = new Float32Array(exec.memory.buffer)
  for (let i = 0; i < nBufs; i++) {
    memView.set(bufData[i], exec.offsets[i] / 4)
  }
  exec.instance.exports.kernel(...exec.offsets)

  const outView = new Float32Array(exec.memory.buffer)
  const result = new Float32Array(numel)
  result.set(outView.subarray(exec.offsets[0] / 4, exec.offsets[0] / 4 + numel))
  return result
}

class PolygradTensor {
  constructor(data, opts = {}) {
    this._ctx = opts._ctx || PolygradTensor._defaultCtx
    this._requiresGrad = opts.requiresGrad || false
    this._grad = null

    if (opts._uop) {
      this._uop = opts._uop
      this._buffer = opts._buffer || null
      this._data = opts._data || null
      this._shape = opts._shape ? [...opts._shape] : []
      this._inputs = opts._inputs || []
    } else {
      let flat, shape
      if (data instanceof Float32Array) {
        flat = new Float32Array(data); shape = [data.length]
      } else if (typeof data === 'number') {
        flat = new Float32Array([data]); shape = [1]
      } else if (Array.isArray(data)) {
        flat = new Float32Array(data); shape = [data.length]
      } else {
        flat = new Float32Array(0); shape = []
      }
      this._shape = shape
      this._data = flat
      this._buffer = _ffi.poly_buffer_f32(this._ctx, flat.length)
      this._uop = this._buffer
      this._inputs = []
    }
  }

  get shape() { return [...this._shape] }
  _isLeaf() { return this._data !== null && this._buffer !== null }

  _collectLeaves(seen) {
    if (!seen) seen = new Set()
    const id = this._buffer || this._uop
    if (seen.has(id)) return []
    seen.add(id)
    if (this._isLeaf()) return [this]
    const leaves = []
    for (const inp of this._inputs) leaves.push(...inp._collectLeaves(seen))
    return leaves
  }

  _realize() {
    if (this._isLeaf()) return
    const leaves = this._collectLeaves()
    const numel = this._shape.reduce((a, b) => a * b, 1) || 1
    const outBuf = _ffi.poly_buffer_f32(this._ctx, numel)
    const store = _ffi.poly_store_val(this._ctx, outBuf, this._uop)
    const sink = _ffi.poly_sink1(this._ctx, store)

    const bufferMap = new Map()
    for (const leaf of leaves) bufferMap.set(leaf._buffer, leaf._data)
    bufferMap.set(outBuf, new Float32Array(numel))

    this._data = _renderAndExec(this._ctx, sink, outBuf, numel, (bufUop) => bufferMap.get(bufUop))
    this._buffer = outBuf
    this._uop = outBuf
    this._inputs = []
  }

  toArray() { this._realize(); return new Float32Array(this._data) }
  item() { return this.toArray()[0] }

  _makeResult(uop, shape, inputs) {
    return new PolygradTensor(null, {
      _ctx: this._ctx, _uop: uop, _shape: shape, _inputs: inputs,
      requiresGrad: inputs.some(t => t._requiresGrad)
    })
  }

  _ensureTensor(other) {
    if (other instanceof PolygradTensor) return other
    if (typeof other === 'number') {
      const c = _ffi.poly_const_float(this._ctx, other)
      return new PolygradTensor(null, { _ctx: this._ctx, _uop: c, _shape: [], _inputs: [] })
    }
    throw new TypeError('Cannot convert to PolygradTensor')
  }

  add(other) {
    other = this._ensureTensor(other)
    return this._makeResult(
      _ffi.poly_alu2(this._ctx, _ffi.OPS.ADD, this._uop, other._uop),
      [...this._shape], [this, other])
  }
  sub(other) {
    other = this._ensureTensor(other)
    return this._makeResult(
      _ffi.poly_alu2(this._ctx, _ffi.OPS.SUB, this._uop, other._uop),
      [...this._shape], [this, other])
  }
  mul(other) {
    other = this._ensureTensor(other)
    return this._makeResult(
      _ffi.poly_alu2(this._ctx, _ffi.OPS.MUL, this._uop, other._uop),
      [...this._shape], [this, other])
  }
  div(other) {
    other = this._ensureTensor(other)
    return this._makeResult(
      _ffi.poly_alu2(this._ctx, _ffi.OPS.FDIV, this._uop, other._uop),
      [...this._shape], [this, other])
  }
  neg() {
    return this._makeResult(
      _ffi.poly_alu1(this._ctx, _ffi.OPS.NEG, this._uop),
      [...this._shape], [this])
  }
  exp2() {
    return this._makeResult(
      _ffi.poly_alu1(this._ctx, _ffi.OPS.EXP2, this._uop),
      [...this._shape], [this])
  }
  log2() {
    return this._makeResult(
      _ffi.poly_alu1(this._ctx, _ffi.OPS.LOG2, this._uop),
      [...this._shape], [this])
  }
  sqrt() {
    return this._makeResult(
      _ffi.poly_alu1(this._ctx, _ffi.OPS.SQRT, this._uop),
      [...this._shape], [this])
  }
  reciprocal() {
    return this._makeResult(
      _ffi.poly_alu1(this._ctx, _ffi.OPS.RECIPROCAL, this._uop),
      [...this._shape], [this])
  }

  sum(axis) {
    if (axis === undefined || axis === null) axis = this._shape.map((_, i) => i)
    if (typeof axis === 'number') axis = [axis]
    const ptr = writeInt64Array(axis)
    const uop = _ffi.poly_reduce_axis(this._ctx, _ffi.OPS.ADD, this._uop, ptr, axis.length)
    polygradModule._free(ptr)
    const axisSet = new Set(axis)
    const newShape = this._shape.filter((_, i) => !axisSet.has(i))
    return this._makeResult(uop, newShape.length ? newShape : [1], [this])
  }

  backward() {
    const allLeaves = this._collectLeaves()
    const gradLeaves = allLeaves.filter(t => t._requiresGrad)
    for (const leaf of gradLeaves) {
      const gradUop = _ffi.poly_grad(this._ctx, this._uop, leaf._buffer)
      if (!gradUop) throw new Error('poly_grad returned NULL')
      const numel = leaf._shape.reduce((a, b) => a * b, 1) || 1
      const gradBuf = _ffi.poly_buffer_f32(this._ctx, numel)
      const store = _ffi.poly_store_val(this._ctx, gradBuf, gradUop)
      const sink = _ffi.poly_sink1(this._ctx, store)

      const bufferMap = new Map()
      for (const l of allLeaves) bufferMap.set(l._buffer, l._data)
      bufferMap.set(gradBuf, new Float32Array(numel))

      const gradResult = _renderAndExec(this._ctx, sink, gradBuf, numel, (bufUop) => bufferMap.get(bufUop))
      leaf._grad = new PolygradTensor(gradResult, { _ctx: this._ctx })
    }
  }
}

PolygradTensor._defaultCtx = null

function buildPolygradExecOnlyRunner(resultTensor) {
  const ctx = resultTensor._ctx
  const leaves = resultTensor._collectLeaves()
  const numel = resultTensor._shape.reduce((a, b) => a * b, 1) || 1
  const outBuf = _ffi.poly_buffer_f32(ctx, numel)
  const store = _ffi.poly_store_val(ctx, outBuf, resultTensor._uop)
  const sink = _ffi.poly_sink1(ctx, store)

  const wasmLenPtr = polygradModule._malloc(4)
  const nBufsPtr = polygradModule._malloc(4)
  const wasmPtr = _ffi.poly_render_kernel_wasm(ctx, sink, wasmLenPtr, nBufsPtr)
  const wasmLen = polygradModule.getValue(wasmLenPtr, 'i32')
  const nBufs = polygradModule.getValue(nBufsPtr, 'i32')
  polygradModule._free(wasmLenPtr)
  polygradModule._free(nBufsPtr)
  if (!wasmPtr || wasmLen === 0) throw new Error('poly_render_kernel_wasm failed')

  const bufferMap = new Map()
  for (const leaf of leaves) bufferMap.set(leaf._buffer, leaf._data)
  bufferMap.set(outBuf, new Float32Array(numel))

  const bufData = new Array(nBufs)
  for (let i = 0; i < nBufs; i++) {
    const bufUop = _ffi.poly_kernel_buf(ctx, i)
    bufData[i] = bufferMap.get(bufUop)
    if (!bufData[i]) throw new Error(`No data binding for kernel buffer param ${i}`)
  }

  const wasmBytes = new Uint8Array(wasmLen)
  wasmBytes.set(polygradModule.HEAPU8.subarray(wasmPtr, wasmPtr + wasmLen))
  polygradModule._free(wasmPtr)

  const key = hashBytes(wasmBytes)
  let exec = _execCache.get(key)

  if (!exec) {
    const offsets = new Array(nBufs)
    let totalBytes = 0
    for (let i = 0; i < nBufs; i++) {
      offsets[i] = totalBytes
      totalBytes += bufData[i].length * 4
    }
    const neededPages = Math.max(1, Math.ceil(totalBytes / 65536))
    const memory = new WebAssembly.Memory({ initial: neededPages })
    const module = new WebAssembly.Module(wasmBytes)
    const instance = new WebAssembly.Instance(module, {
      env: { memory }, math: mathImports
    })
    exec = { instance, memory, memPages: neededPages, nBufs, offsets, totalBytes }
    _execCache.set(key, exec)
  }

  // Pre-populate memory with input data
  const memView = new Float32Array(exec.memory.buffer)
  for (let i = 0; i < nBufs; i++) {
    memView.set(bufData[i], exec.offsets[i] / 4)
  }

  const cachedOffsets = exec.offsets
  const cachedInstance = exec.instance
  return {
    run() {
      cachedInstance.exports.kernel(...cachedOffsets)
    }
  }
}

function makePolygradExecOnlyRunner(opName, a, b) {
  if (opName === 'add') {
    const ta = new PolygradTensor(a)
    const tb = new PolygradTensor(b)
    return buildPolygradExecOnlyRunner(ta.add(tb))
  }
  if (opName === 'mul') {
    const ta = new PolygradTensor(a)
    const tb = new PolygradTensor(b)
    return buildPolygradExecOnlyRunner(ta.mul(tb))
  }
  if (opName === 'sum') {
    const ta = new PolygradTensor(a)
    return buildPolygradExecOnlyRunner(ta.sum())
  }
  throw new Error(`Unknown op for polygrad exec runner: ${opName}`)
}

function makeTfExecOnlyRunner(opName, a, b) {
  const ta = tf.tensor1d(a)
  const tb = b ? tf.tensor1d(b) : null

  if (opName === 'add') {
    return {
      run() {
        const out = ta.add(tb)
        out.dataSync()
        out.dispose()
      },
      dispose() { ta.dispose(); tb.dispose() }
    }
  }
  if (opName === 'mul') {
    return {
      run() {
        const out = ta.mul(tb)
        out.dataSync()
        out.dispose()
      },
      dispose() { ta.dispose(); tb.dispose() }
    }
  }
  if (opName === 'sum') {
    return {
      run() {
        const out = ta.sum()
        out.dataSync()
        out.dispose()
      },
      dispose() { ta.dispose() }
    }
  }
  ta.dispose()
  if (tb) tb.dispose()
  throw new Error(`Unknown op for tf.js exec runner: ${opName}`)
}

// ── UI helpers ──

const NUM_TESTS = 6

function initUI() {
  const dots = document.getElementById('dots')
  for (let i = 0; i < NUM_TESTS; i++) {
    const d = document.createElement('span')
    d.className = 'dot'; d.id = `dot-${i}`; d.textContent = i + 1
    dots.appendChild(d)
  }
}

function setDotState(idx, state) {
  document.getElementById(`dot-${idx}`).className = 'dot ' + state
}

function setStatus(text) {
  document.getElementById('statusText').textContent = text
}

function setBadge(block, passed, msg) {
  const badge = block.querySelector('.badge')
  badge.className = 'badge ' + (passed ? 'pass' : 'fail')
  badge.textContent = passed ? 'PASS' : ('FAIL' + (msg ? ': ' + msg : ''))
}

function setDetails(block, html) {
  block.querySelector('.details').innerHTML = html
}

// ── Test definitions ──

const tests = []

// --- Test 1: Element-wise Correctness ---
tests.push({
  name: 'Element-wise Correctness',
  desc: 'Same random data through add, mul, neg — overlaid histograms should match exactly.',
  canvasCount: 3,
  async run(block) {
    const N = 2000
    const dataA = randFloat32(N, -5, 5)
    const dataB = randFloat32(N, -5, 5)

    const ops = [
      { name: 'add(a, b)', arity: 2, polygradFn: (a, b) => a.add(b), tfFn: (a, b) => a.add(b) },
      { name: 'mul(a, b)', arity: 2, polygradFn: (a, b) => a.mul(b), tfFn: (a, b) => a.mul(b) },
      { name: 'neg(a)', arity: 1, polygradFn: (a) => a.neg(), tfFn: (a) => a.neg() }
    ]

    let allPass = true
    let detailHtml = ''
    const canvases = block.querySelectorAll('canvas')

    for (let i = 0; i < ops.length; i++) {
      const op = ops[i]

      // polygrad
      const ta = new PolygradTensor(dataA)
      const tb = new PolygradTensor(dataB)
      const polygradOut = op.arity === 2 ? op.polygradFn(ta, tb) : op.polygradFn(ta)
      const polygradResult = polygradOut.toArray()

      // tf.js
      const tfa = tf.tensor1d(dataA)
      const tfb = tf.tensor1d(dataB)
      const tfOut = op.arity === 2 ? op.tfFn(tfa, tfb) : op.tfFn(tfa)
      const tfResult = tensorDataAndDispose(tfOut)
      tfa.dispose(); tfb.dispose()

      const err = maxAbsError(polygradResult, tfResult)
      const pass = err < 1e-4
      if (!pass) allPass = false

      const { ctx, w, h } = setupCanvas(canvases[i])
      drawMultiHistogram(ctx, w, h, [
        { data: Array.from(polygradResult), color: '#58a6ff', label: 'polygrad' },
        { data: Array.from(tfResult), color: '#ffa657', label: 'tf.js' }
      ], { title: op.name })

      detailHtml += `<span class="label">${op.name}:</span> max error = <span class="${pass ? 'pass-val' : 'fail-val'}">${err.toExponential(2)}</span>  `
    }

    setDetails(block, detailHtml)
    return { passed: allPass }
  }
})

// --- Test 2: Transcendental Functions ---
tests.push({
  name: 'Transcendental Functions',
  desc: 'exp2, sqrt, log2 on positive random data — error distributions should be near zero.',
  canvasCount: 3,
  async run(block) {
    const N = 2000
    const data = randFloat32(N, 0.1, 8)

    const ops = [
      { name: 'exp2(x)', polygradFn: (a) => a.exp2(), tfFn: (a) => tf.tidy(() => tf.pow(tf.scalar(2), a)) },
      { name: 'sqrt(x)', polygradFn: (a) => a.sqrt(), tfFn: (a) => a.sqrt() },
      { name: 'log2(x)', polygradFn: (a) => a.log2(), tfFn: (a) => tf.tidy(() => tf.log(a).div(Math.log(2))) }
    ]

    let allPass = true
    let detailHtml = ''
    const canvases = block.querySelectorAll('canvas')

    for (let i = 0; i < ops.length; i++) {
      const op = ops[i]
      const ta = new PolygradTensor(data)
      const polygradResult = op.polygradFn(ta).toArray()
      const tfa = tf.tensor1d(data)
      const tfResult = tensorDataAndDispose(op.tfFn(tfa))
      tfa.dispose()

      // Plot error distribution
      const errors = new Float32Array(N)
      for (let j = 0; j < N; j++) errors[j] = polygradResult[j] - tfResult[j]
      const err = maxAbsError(polygradResult, tfResult)
      const pass = err < 1e-3
      if (!pass) allPass = false

      const { ctx, w, h } = setupCanvas(canvases[i])
      drawHistogram(ctx, w, h, Array.from(errors), {
        title: op.name + ' error', color: pass ? '#3fb950' : '#f85149'
      })

      detailHtml += `<span class="label">${op.name}:</span> max |err| = <span class="${pass ? 'pass-val' : 'fail-val'}">${err.toExponential(2)}</span>  `
    }

    setDetails(block, detailHtml)
    return { passed: allPass }
  }
})

// --- Test 3: Operation Speed ---
tests.push({
  name: 'Operation Speed',
  desc: 'Benchmark add, mul, sum at sizes 256 / 2048 / 16384 with split metrics: compile+execute vs execute-only.',
  canvasCount: 1,
  async run(block) {
    const sizes = [256, 2048, 16384]
    const sampleMs = 800
    const groups = []
    const details = []

    // Warm up tf.js
    await tf.setBackend('cpu')
    await tf.ready()
    const warmup = tf.tensor1d(new Float32Array(64))
    const warmupOut = warmup.add(warmup)
    warmupOut.dataSync()
    warmupOut.dispose()
    warmup.dispose()

    for (const sz of sizes) {
      const a = randFloat32(sz)
      const b = randFloat32(sz)

      // --- add ---
      const polygradAddCompile = await benchmarkIterationsByTime(() => {
        const ta1 = new PolygradTensor(a)
        const tb1 = new PolygradTensor(b)
        ta1.add(tb1).toArray()
      }, { warmupMs: 200, sampleMs })

      const polygradAddExecRunner = makePolygradExecOnlyRunner('add', a, b)
      const polygradAddExec = await benchmarkIterationsByTime(() => {
        polygradAddExecRunner.run()
      }, { warmupMs: 200, sampleMs })

      const tfjsAddExecRunner = makeTfExecOnlyRunner('add', a, b)
      const tfjsAddExec = await benchmarkIterationsByTime(() => {
        tfjsAddExecRunner.run()
      }, { warmupMs: 200, sampleMs })
      tfjsAddExecRunner.dispose()

      const tfjsAddCold = await benchmarkIterationsByTime(() => {
        const tfa1 = tf.tensor1d(a)
        const tfb1 = tf.tensor1d(b)
        const out = tfa1.add(tfb1)
        out.dataSync()
        out.dispose()
        tfa1.dispose()
        tfb1.dispose()
      }, { warmupMs: 200, sampleMs })

      groups.push({
        label: `add ${sz}`,
        bars: [
          { value: polygradAddCompile.iterPerSec, color: '#58a6ff', label: 'polygrad compile+exec' },
          { value: polygradAddExec.iterPerSec, color: '#3fb950', label: 'polygrad exec-only' },
          { value: tfjsAddExec.iterPerSec, color: '#ffa657', label: 'tf.js exec-only' }
        ]
      })

      // --- mul ---
      const polygradMulCompile = await benchmarkIterationsByTime(() => {
        const ta2 = new PolygradTensor(a)
        const tb2 = new PolygradTensor(b)
        ta2.mul(tb2).toArray()
      }, { warmupMs: 200, sampleMs })

      const polygradMulExecRunner = makePolygradExecOnlyRunner('mul', a, b)
      const polygradMulExec = await benchmarkIterationsByTime(() => {
        polygradMulExecRunner.run()
      }, { warmupMs: 200, sampleMs })

      const tfjsMulExecRunner = makeTfExecOnlyRunner('mul', a, b)
      const tfjsMulExec = await benchmarkIterationsByTime(() => {
        tfjsMulExecRunner.run()
      }, { warmupMs: 200, sampleMs })
      tfjsMulExecRunner.dispose()

      const tfjsMulCold = await benchmarkIterationsByTime(() => {
        const tfa2 = tf.tensor1d(a)
        const tfb2 = tf.tensor1d(b)
        const out = tfa2.mul(tfb2)
        out.dataSync()
        out.dispose()
        tfa2.dispose()
        tfb2.dispose()
      }, { warmupMs: 200, sampleMs })

      groups.push({
        label: `mul ${sz}`,
        bars: [
          { value: polygradMulCompile.iterPerSec, color: '#58a6ff', label: 'polygrad compile+exec' },
          { value: polygradMulExec.iterPerSec, color: '#3fb950', label: 'polygrad exec-only' },
          { value: tfjsMulExec.iterPerSec, color: '#ffa657', label: 'tf.js exec-only' }
        ]
      })

      // --- sum ---
      const polygradSumCompile = await benchmarkIterationsByTime(() => {
        const ta3 = new PolygradTensor(a)
        ta3.sum().toArray()
      }, { warmupMs: 200, sampleMs })

      const polygradSumExecRunner = makePolygradExecOnlyRunner('sum', a, null)
      const polygradSumExec = await benchmarkIterationsByTime(() => {
        polygradSumExecRunner.run()
      }, { warmupMs: 200, sampleMs })

      const tfjsSumExecRunner = makeTfExecOnlyRunner('sum', a, null)
      const tfjsSumExec = await benchmarkIterationsByTime(() => {
        tfjsSumExecRunner.run()
      }, { warmupMs: 200, sampleMs })
      tfjsSumExecRunner.dispose()

      const tfjsSumCold = await benchmarkIterationsByTime(() => {
        const tfa3 = tf.tensor1d(a)
        const out = tfa3.sum()
        out.dataSync()
        out.dispose()
        tfa3.dispose()
      }, { warmupMs: 200, sampleMs })

      groups.push({
        label: `sum ${sz}`,
        bars: [
          { value: polygradSumCompile.iterPerSec, color: '#58a6ff', label: 'polygrad compile+exec' },
          { value: polygradSumExec.iterPerSec, color: '#3fb950', label: 'polygrad exec-only' },
          { value: tfjsSumExec.iterPerSec, color: '#ffa657', label: 'tf.js exec-only' }
        ]
      })

      details.push(
        `<span class="label">${sz} elems:</span> ` +
        `add c+e <span class="polygrad-val">${polygradAddCompile.iterPerSec.toFixed(1)}</span>, polygrad-exec <span class="pass-val">${polygradAddExec.iterPerSec.toFixed(1)}</span>, tfjs-exec <span class="tfjs-val">${tfjsAddExec.iterPerSec.toFixed(1)}</span>, tfjs-cold ${tfjsAddCold.iterPerSec.toFixed(1)} it/s; ` +
        `mul c+e <span class="polygrad-val">${polygradMulCompile.iterPerSec.toFixed(1)}</span>, polygrad-exec <span class="pass-val">${polygradMulExec.iterPerSec.toFixed(1)}</span>, tfjs-exec <span class="tfjs-val">${tfjsMulExec.iterPerSec.toFixed(1)}</span>, tfjs-cold ${tfjsMulCold.iterPerSec.toFixed(1)} it/s; ` +
        `sum c+e <span class="polygrad-val">${polygradSumCompile.iterPerSec.toFixed(1)}</span>, polygrad-exec <span class="pass-val">${polygradSumExec.iterPerSec.toFixed(1)}</span>, tfjs-exec <span class="tfjs-val">${tfjsSumExec.iterPerSec.toFixed(1)}</span>, tfjs-cold ${tfjsSumCold.iterPerSec.toFixed(1)} it/s`
      )
    }

    const canvas = block.querySelector('canvas')
    const { ctx, w, h } = setupCanvas(canvas)
    drawBarChart(ctx, w, h, groups, { yLabel: 'iterations / sec' })

    let detailHtml = '<span class="label">Backend:</span> tf.js CPU (JS) vs polygrad (compiled WASM kernels)<br>'
    detailHtml += `<span class="label">Method:</span> fixed ${sampleMs}ms sampling window after 200ms warmup; higher is better<br>`
    detailHtml += details.join('<br>') + '<br>'
    detailHtml += '<span class="label">Legend:</span> blue=polygrad compile+execute, green=polygrad execute-only, orange=tf.js execute-only<br>'
    detailHtml += '<span class="label">Note:</span> compile+execute includes graph build + kernel render + WASM compile + instantiate + execute'
    setDetails(block, detailHtml)
    return { passed: true }
  }
})

// --- Test 4: Gradient Descent ---
tests.push({
  name: 'Gradient Descent Training',
  desc: 'Minimize sum((x - [3, 1, 4])^2). Starting from [0, 0, 0], lr=0.1, 30 steps. X-axis = wall-clock time — shows which converges faster.',
  canvasCount: 1,
  async run(block) {
    const target = [3, 1, 4]
    const lr = 0.1
    const steps = 30

    // --- polygrad ---
    let params = new Float32Array([0, 0, 0])
    const polygradLosses = []
    const polygradTimes = []
    const t0polygrad = performance.now()

    for (let i = 0; i < steps; i++) {
      const st = performance.now()
      const x = new PolygradTensor(params, { requiresGrad: true })
      const t = new PolygradTensor(new Float32Array(target))
      const diff = x.sub(t)
      const sq = diff.mul(diff)
      const loss = sq.sum()

      loss.backward()
      if (!x._grad) throw new Error('polygrad backward produced null gradient')
      const grad = x._grad.toArray()

      const lossVal = loss.item()
      polygradLosses.push(lossVal)

      for (let j = 0; j < params.length; j++) params[j] -= lr * grad[j]
      polygradTimes.push(performance.now() - st)
    }
    const polygradTotal = performance.now() - t0polygrad

    // --- tf.js ---
    await tf.setBackend('cpu')
    await tf.ready()
    const xVar = tf.variable(tf.tensor1d([0, 0, 0]))
    const tTarget = tf.tensor1d(target)
    const tfjsLosses = []
    const tfjsTimes = []
    const t0tfjs = performance.now()

    for (let i = 0; i < steps; i++) {
      const st = performance.now()
      const lossFn = () => xVar.sub(tTarget).square().sum()
      const grads = tf.grads(lossFn)
      const lossVal = lossFn()
      tfjsLosses.push(lossVal.dataSync()[0])
      lossVal.dispose()

      const [gx] = grads([xVar])
      xVar.assign(xVar.sub(gx.mul(lr)))
      gx.dispose()
      tfjsTimes.push(performance.now() - st)
    }
    const tfjsTotal = performance.now() - t0tfjs
    xVar.dispose(); tTarget.dispose()

    // Plot: x-axis = cumulative time (ms) so we see which converges faster
    const polygradCumTime = [], tfjsCumTime = []
    let polygradAcc = 0, tfjsAcc = 0
    for (let i = 0; i < steps; i++) {
      polygradAcc += polygradTimes[i]; polygradCumTime.push(polygradAcc)
      tfjsAcc += tfjsTimes[i]; tfjsCumTime.push(tfjsAcc)
    }
    const canvas = block.querySelector('canvas')
    const { ctx, w, h } = setupCanvas(canvas)
    drawLineChart(ctx, w, h, [
      { xs: polygradCumTime, ys: polygradLosses, color: '#58a6ff', label: 'polygrad', lineWidth: 2 },
      { xs: tfjsCumTime, ys: tfjsLosses, color: '#ffa657', label: 'tf.js', lineWidth: 2 }
    ], { xLabel: 'time (ms)', yLabel: 'loss' })

    const polygradFinal = polygradLosses[polygradLosses.length - 1]
    const tfjsFinal = tfjsLosses[tfjsLosses.length - 1]
    const converged = polygradFinal < 0.01 && tfjsFinal < 0.01

    let detailHtml = `<span class="label">polygrad:</span> <span class="polygrad-val">${polygradTotal.toFixed(0)}ms total, final loss=${polygradFinal.toExponential(2)}, avg step=${mean(polygradTimes).toFixed(1)}ms</span><br>`
    detailHtml += `<span class="label">tf.js:</span> <span class="tfjs-val">${tfjsTotal.toFixed(0)}ms total, final loss=${tfjsFinal.toExponential(2)}, avg step=${mean(tfjsTimes).toFixed(1)}ms</span><br>`
    detailHtml += `<span class="label">Converged:</span> <span class="${converged ? 'pass-val' : 'fail-val'}">${converged ? 'yes' : 'no'}</span>`
    setDetails(block, detailHtml)
    return { passed: converged }
  }
})

// --- Test 5: Autograd Accuracy ---
tests.push({
  name: 'Autograd Accuracy',
  desc: 'Compare analytical gradients with polygrad and tf.js computed gradients at specific points.',
  useTable: true,
  async run(block) {
    const cases = [
      {
        expr: 'sum(x * x)',
        point: [2, 3, -1],
        analytical: [4, 6, -2],
        polygrad(data) {
          const x = new PolygradTensor(new Float32Array(data), { requiresGrad: true })
          const loss = x.mul(x).sum()
          loss.backward()
          return x._grad.toArray()
        },
        tfjs(data) {
          const x = tf.tensor1d(data)
          const f = (x) => x.mul(x).sum()
          const g = tf.grad(f)(x)
          const r = g.dataSync()
          x.dispose(); g.dispose()
          return r
        }
      },
      {
        expr: 'sum(-x)',
        point: [1, 5, 10],
        analytical: [-1, -1, -1],
        polygrad(data) {
          const x = new PolygradTensor(new Float32Array(data), { requiresGrad: true })
          const loss = x.neg().sum()
          loss.backward()
          return x._grad.toArray()
        },
        tfjs(data) {
          const x = tf.tensor1d(data)
          const g = tf.grad((x) => x.neg().sum())(x)
          const r = g.dataSync()
          x.dispose(); g.dispose()
          return r
        }
      },
      {
        expr: 'sum(x * 3 + 1)',
        point: [0, 7, -2],
        analytical: [3, 3, 3],
        polygrad(data) {
          const x = new PolygradTensor(new Float32Array(data), { requiresGrad: true })
          const loss = x.mul(3).add(1).sum()
          loss.backward()
          return x._grad.toArray()
        },
        tfjs(data) {
          const x = tf.tensor1d(data)
          const g = tf.grad((x) => x.mul(3).add(1).sum())(x)
          const r = g.dataSync()
          x.dispose(); g.dispose()
          return r
        }
      },
      {
        expr: 'sum(sqrt(x))',
        point: [4, 9, 16],
        analytical: [0.25, 1/6, 0.125],
        polygrad(data) {
          const x = new PolygradTensor(new Float32Array(data), { requiresGrad: true })
          const loss = x.sqrt().sum()
          loss.backward()
          return x._grad.toArray()
        },
        tfjs(data) {
          const x = tf.tensor1d(data)
          const g = tf.grad((x) => x.sqrt().sum())(x)
          const r = g.dataSync()
          x.dispose(); g.dispose()
          return r
        }
      }
    ]

    const table = block.querySelector('.result-table')
    let html = '<tr><th>Expression</th><th>Point</th><th>Analytical</th><th>polygrad</th><th>tf.js</th><th>Status</th></tr>'
    let allPass = true

    for (const c of cases) {
      const polygradGrad = c.polygrad(c.point)
      const tfjsGrad = c.tfjs(c.point)
      const ana = new Float32Array(c.analytical)

      const polygradErr = maxAbsError(polygradGrad, ana)
      const tfjsErr = maxAbsError(tfjsGrad, ana)
      const pass = polygradErr < 0.05 && tfjsErr < 0.05
      if (!pass) allPass = false

      const fmt = (arr) => '[' + Array.from(arr).map(v => v.toFixed(3)).join(', ') + ']'
      html += `<tr>
        <td>${c.expr}</td>
        <td>${fmt(c.point)}</td>
        <td>${fmt(ana)}</td>
        <td class="cell-polygrad">${fmt(polygradGrad)}</td>
        <td class="cell-tfjs">${fmt(tfjsGrad)}</td>
        <td class="${pass ? 'cell-pass' : 'cell-fail'}">${pass ? 'PASS' : 'FAIL'}</td>
      </tr>`
    }

    table.innerHTML = html
    return { passed: allPass }
  }
})

// --- Test 6: Library & Kernel Size ---
tests.push({
  name: 'Library Size & Architecture',
  desc: 'Comparison of download size and execution model. polygrad compiles custom WASM kernels per operation.',
  useTable: true,
  async run(block) {
    // Estimate sizes
    let polygradJsSize = '?', polygradWasmSize = '?'
    try {
      const jsResp = await fetch('../../../build/polygrad.js')
      polygradJsSize = ((await jsResp.clone().arrayBuffer()).byteLength / 1024).toFixed(0)
      const wasmResp = await fetch('../../../build/polygrad.wasm')
      polygradWasmSize = ((await wasmResp.clone().arrayBuffer()).byteLength / 1024).toFixed(0)
    } catch (e) {}

    // Measure a kernel size
    const dummy = new PolygradTensor(new Float32Array([1, 2, 3]))
    const added = dummy.add(dummy)
    const numel = 3
    const outBuf = _ffi.poly_buffer_f32(PolygradTensor._defaultCtx, numel)
    const store = _ffi.poly_store_val(PolygradTensor._defaultCtx, outBuf, added._uop)
    const sink = _ffi.poly_sink1(PolygradTensor._defaultCtx, store)
    const wasmLenPtr = polygradModule._malloc(4)
    const nBufsPtr = polygradModule._malloc(4)
    const wasmPtr = _ffi.poly_render_kernel_wasm(PolygradTensor._defaultCtx, sink, wasmLenPtr, nBufsPtr)
    const kernelSize = polygradModule.getValue(wasmLenPtr, 'i32')
    polygradModule._free(wasmLenPtr); polygradModule._free(nBufsPtr)
    if (wasmPtr) polygradModule._free(wasmPtr)

    const table = block.querySelector('.result-table')
    table.innerHTML = `
      <tr><th>Metric</th><th class="cell-polygrad">polygrad</th><th class="cell-tfjs">tf.js</th></tr>
      <tr><td>Execution model</td><td>Compiled WASM kernels</td><td>Pre-built JS/WASM kernels</td></tr>
      <tr><td>JS loader size</td><td class="cell-polygrad">${polygradJsSize} KB</td><td class="cell-tfjs">~60 KB (core)</td></tr>
      <tr><td>WASM/binary size</td><td class="cell-polygrad">${polygradWasmSize} KB</td><td class="cell-tfjs">~1,500 KB (cpu backend)</td></tr>
      <tr><td>Total download</td><td class="cell-polygrad">${(+polygradJsSize + +polygradWasmSize) || '?'} KB</td><td class="cell-tfjs">~1,600 KB</td></tr>
      <tr><td>Per-op kernel size</td><td class="cell-polygrad">${kernelSize} bytes (add[3])</td><td class="cell-tfjs">N/A (shared)</td></tr>
      <tr><td>Autograd</td><td class="cell-polygrad">Symbolic (C compiler)</td><td class="cell-tfjs">Tape-based (JS)</td></tr>
      <tr><td>Backend</td><td class="cell-polygrad">CPU (WASM)</td><td class="cell-tfjs">CPU / WebGL / WASM</td></tr>
      <tr><td>Kernel fusion</td><td class="cell-polygrad">Compiler-level</td><td class="cell-tfjs">XLA (limited)</td></tr>
    `
    return { passed: true }
  }
})

// ── Build test UI ──

function buildTestBlocks() {
  const container = document.getElementById('testContainer')
  for (let i = 0; i < tests.length; i++) {
    const t = tests[i]
    const block = document.createElement('div')
    block.className = 'test-block'; block.id = `test-${i}`

    let canvasHtml = ''
    if (t.useTable) {
      canvasHtml = '<table class="result-table"></table>'
    } else if (t.canvasCount === 1) {
      canvasHtml = '<div class="canvas-wrap"><canvas></canvas></div>'
    } else if (t.canvasCount > 1) {
      canvasHtml = '<div class="canvas-row">'
      for (let j = 0; j < t.canvasCount; j++) {
        canvasHtml += '<div class="canvas-wrap"><canvas></canvas></div>'
      }
      canvasHtml += '</div>'
    }

    block.innerHTML = `
      <div class="test-header">
        <h3>${i + 1}. ${t.name}</h3>
        <span class="badge pending">PENDING</span>
      </div>
      <div class="description">${t.desc}</div>
      ${canvasHtml}
      <div class="details"></div>
    `
    container.appendChild(block)
  }
}

// ── Main runner ──

async function runAllTests() {
  const btn = document.getElementById('runBtn')
  btn.disabled = true

  let passed = 0
  for (let i = 0; i < tests.length; i++) {
    setDotState(i, 'running')
    setStatus(`Running test ${i + 1}/${NUM_TESTS}...`)
    const block = document.getElementById(`test-${i}`)

    try {
      const result = await tests[i].run(block)
      setBadge(block, result.passed)
      setDotState(i, result.passed ? 'pass' : 'fail')
      if (result.passed) passed++
    } catch (err) {
      console.error(`Test ${i + 1} error:`, err)
      setBadge(block, false, err.message)
      setDotState(i, 'fail')
      setDetails(block, `<span class="fail-val">${err.message}</span>`)
    }
  }

  setStatus(`Complete: ${passed}/${NUM_TESTS} passed`)
  btn.disabled = false
}

// ── Init ──

async function main() {
  initUI()
  buildTestBlocks()

  setStatus('Loading polygrad WASM...')
  try {
    await initPolygrad()
    document.getElementById('polygradSize').textContent = 'polygrad: ready'
  } catch (e) {
    setStatus('Failed to load polygrad: ' + e.message)
    console.error('polygrad init error:', e)
    return
  }

  setStatus('Loading tf.js...')
  try {
    await tf.setBackend('cpu')
    await tf.ready()
    document.getElementById('tfjsSize').textContent = 'tf.js: ' + tf.getBackend()
  } catch (e) {
    setStatus('Failed to load tf.js: ' + e.message)
    console.error('tf.js init error:', e)
    return
  }

  setStatus('Ready')
  document.getElementById('runBtn').disabled = false
}

main()
</script>
</body>
</html>
